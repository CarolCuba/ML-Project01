\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage[portuges,brazil,english]{babel}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{float}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Predicting Diamonds Price: A Linear Regression Assigment}

\author{\IEEEauthorblockN{Carolina F. Cuba}
\IEEEauthorblockA{
226004 \\
carolinacuba23@gmail.com}
\and
\IEEEauthorblockN{LEO}
\IEEEauthorblockA{
xxx \\
xxxxxxxxxx}}

\maketitle

\section{Introduction}

Within the field of Machine Learning there are three main categories in which an algorithm can be classified: Supervised Learning Based, Unsupervised Learning Based and Enhancement Learning Based. Supervised systems are developed over a data base that has been already labeled, therefore, we have a previously knowledge of the expected predictions that our model has to return. Supervised learning is typically done in the context of solving both classification and regression problems.
While classification problems map an input to a label, regression ones focus on finding a model that better describes the relationship between the input and output continuous value.\par

Simple Linear Regression seeks to perform a predictive analysis over a input data base and its final result is a linear equation(1) that minimize the prediction error, hence the alternative name given to this function: Cost Function.

\begin{equation}
h_\theta(x)= \theta_0 x_0 + \theta_1 x_1 + \theta_2 x_2 + ... + \theta_n x_n
\end{equation}

The cost function is used to define the best values for $\theta$ parameters that are multiplied to each respectively feature extracted from the data base. In order to find those values, it was created a method called Gradient Descent that consist on applying partial derivatives on the cost function along a series of iterations pre-defined by the user. After each iteration, the $\theta$ parameters are updated given the new cost value and multiplied by a $\alpha$ scalar (learning rate).

\begin{equation}
\theta_n := \theta_n - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^(i)) - y(i))x(i)
\end{equation}

The equation (2) must be repeated by a given number of iterations until the cost reaches a convergence value that coincides with the global minimum of the (1) equation. The importance of the learning rate is that it determines the velocity in which the gradient descent will reach the global minimum. The learning rate has to be set to an appropriate value (neither to low or to high). If it is set to a high value, the gradient descent will not reach the minimum because $\alpha$ will bounces back and forth in the function. If the learning rate is set to a value too low, the gradient descent will eventually reach the minimum, however it will maybe take too much time.\par

The main objective of this assignment is to explore alternatives to linear regression algorithm to solve the problem of predicting the price of diamonds from its attributes using the Diamonds Data Set (54.000 samples). In the "\textit{Activities}" section we explain all the procedures utilized to implement linear regression utilizing both batch and stochastic gradient descent. We also implement a solution for this problem using normalized equations. In the "\textit{Experiments}" section we present all experiments realized, we intended to show relation between cost and number of iterations when changing the method of convergence (gradient descent/normalized equation), the gradient descent itself (batch/stochastic) and the value of learning rate. Finally, on "\textit{Conclusion}" section, we describe all are conclusions after the experimentation.\par

\section{Activities}
In this section we describe all the procedures implemented in order to solve the problem of pricing diamonds. Besides implementing linear regression using batch gradient descent, we also implemented a normalize equation solution for the same problem in order to compare the results and the processing time. This also was our motivation to implement a solution based on stochastic gradient descent.\par
Also, in this section we explain all pre-processing techniques used to prepare the data set in order to achieve better results, among then we can mention: Outliers removal and Dummy feature representation.\par

\subsection{Data Preparation}	
    A requirement for any computerized regression technique is that all data needs to be placed in discretized values and, in our case, three columns were presented as classes: cut, color and clarity. Fortunately, the semantic information of the classes was already given in the dataset description. As an example, the feature 'cut' represents the quality of the cut, as said in the previous section, and it's values are classes, varying among 'fair', 'good', 'very good', 'premium', and 'ideal' in its respective order of quality. That information of the quality order was provided by the description of the dataset.
    
    Thanks to that knowledge, it was decided to use a dummy coding for discretizing the values. That means that we keep the number of features by giving each class a different value. These values respect the semantic increase of quality of the class, i.e. 'fair' = 1, 'good' = 2, 'very good' = 3.
    
    Also, five features are used to represent two pieces of information: x, y, z, width and table. The size of the diamond is represented by x, y, and z while the width and table represent the correlation among of these dimensions in percentage. Therefore, we combined x,y,z into a new feature called volume with the correlation among them still being expressed on the width and table features.
    
    The last pre-processing step in preparation was the normalization of the feature values from a range of 0 to 1. This allows all the features to have similar weights on the gradient descent. It is not always a bad idea to have features weighting differently during the fitting of the model, but due to our team's lack of specific knowledge about diamonds, a less knowledge-driven approach was taken.
    
    With the data prepared for our method, in order to test our model, we started by shuffling our dataset and reserving 15\% of it for future testing, using the remaining 85\% for training. This testing set was put aside until the final results so we wouldn't be biased when presenting our final model. Right after, the training dataset was divided again, with 20\% of it being picked for validation and the remaining 80\% used for the fitness of the model.
    
    After some analysis of the dataset, it was clear that some samples had inconsistent data. There were, for instance, diamonds with volume equal to zero. In that scenario, we used the difference between the mean and the standard deviation of the volume, depth and table columns to remove some of the outliers.
    
\subsection{Implementation}
	As said on previous sessions, this assignment focus on the implementation of three variations of linear regression algorithm to solve the problem of pricing diamonds.\par
    The first implementation was the batch gradient descent. This variation is know for compute the gradient using the whole data base in each iteration. In this case, the algorithm moves almost directly towards an optimum solution. Batch gradient descend really works good on linear regression, were we have convex functions and the global minimum is ensured.\par
    Secondly, we have implemented the stochastic version of gradient descend (SGD) which updates the $\theta$ parameters using a single sample each time. SGD works better on functions that have multiple local minima, because each new iteration tends to remove the model from a local minima to a better one. Besides, another advantage of SGD is that this variation is relatively faster than the batch gradient descent in large data sets.\par
    Finally, we also implemented a normally equation alternative solution this problem. This algorithm does not perform a gradient descend on a function since it directly finds the right values to the $\theta$ parameters using an equation (3) based on linear algebra theory, therefore there is not need of finding the right value of $\alpha$ and there is not need to use a series of iterations.\par

\begin{equation}
\theta = (X^T X)^{-1} X^T y
\end{equation}

This approach, however, only works for linear regression problems, where the model is represented by a convex function. Moreover, this approach can be used for too large data sets because it consumes a lot of RAM memory and its complexity is of O\((n^3)\) .\par

\section{Experiments}


\section{Conclusion}

\begin{thebibliography}{00}
\bibitem{b1} D. Ciregan, U. Meier and J. Schmidhuber, "Multi-column deep neural networks for image classification," 2012 IEEE Conference on Computer Vision and Pattern Recognition, Providence, RI, 2012, pp. 3642-3649.

\bibitem{b2} Aristidis Likas, Nikos Vlassis, Jakob J. Verbeek, "The global k-means clustering algorithm, "In Pattern Recognition, Volume 36, Issue 2, 2003.

\bibitem{b3} Shehroz S. Khan, Amir Ahmad, "Cluster center initialization algorithm for K-means clustering, "In Pattern Recognition Letters, Volume 25, Issue 11, 2004, Pages 1293-1302

\bibitem{b4} Mark R., "Principal Component Analysis, 2009.

\bibitem{b5} Aristidis Likas, Nikos Vlassis, Jakob J. Verbeek, "The global k-means clustering algorithm, "In Pattern Recognition, Volume 36, Issue 2, 2003.

\bibitem{b6} MacQueen, J. "Some methods for classification and analysis of multivariate observations. "Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics,
281--297, University of California Press, Berkeley

\bibitem{b7} I.T. Jolliffe, "Principal Component Analysis, "Springer Series in Statistics, Springer-Verlag New York, 2002, 978-1-4419-2999-0.

\bibitem{b8} ha, Hongyuan and He, Xiaofeng and Ding, Chris and Simon, Horst and Gu, Ming, "Spectral Relaxation for K-means Clustering," Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic, 2001. Proceedings., 2001, pp. 1057--1064.

\bibitem{b9} Ng, Andrew Y. and Zheng, Alice X. and Jordan, Michael I., "Stable Algorithms for Link Analysis, "Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2001, New Orleans, Louisiana, USA, ppt. 258--266.

\bibitem{b10} Eckart, Carl
and Young, Gale, "The approximation of one matrix by another of lower rank, "Psychometrika, 1936, 1, ppt. 211--218.

\bibitem{b11} Hassani, Marwan
and Seidl, Thomas, "Using internal evaluation measures to validate the quality of diverse stream clustering algorithms, "Vietnam Journal of Computer Science, 2017, 4, ppt. 171--183.

\bibitem{b12} Anna, Huang
"Similarity Measures for Text Document Clustering", Department of Computer Science,The University of Waikato, Hamilton, New Zealand, 2008.


\end{thebibliography}


\end{document}
